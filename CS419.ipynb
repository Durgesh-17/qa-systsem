{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gZ3WRl-8nZU8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DKTdNJBvna0p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Concatenate, Dense, Dropout, MultiHeadAttention, Attention\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vrNTBmGwogyS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RGQHJAG2nlA4"
      },
      "outputs": [],
      "source": [
        "word_embeddings = np.load(( \"./weights_matrix_100D.npy\"), allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dx2YK5HfoJiq"
      },
      "outputs": [],
      "source": [
        "with open('traindata.pkl', 'rb') as handle:\n",
        "    train_df = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pZSViEQ0oMjf"
      },
      "outputs": [],
      "source": [
        "#train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wZS6ONamoQYA"
      },
      "outputs": [],
      "source": [
        "with open('./data/word_vocab.pkl', \"rb\") as wv, \\\n",
        "      open('./data/word2index.pkl', \"rb\") as wi, \\\n",
        "         open('./data/index2word.pkl', \"rb\") as iw:\n",
        "         word_vocab = pickle.load(wv)\n",
        "         word2idx = pickle.load(wi)\n",
        "         idx2word = pickle.load(iw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sM6OpfQQoSeY"
      },
      "outputs": [],
      "source": [
        "max_contex_length = 200\n",
        "max_question_length = 30\n",
        "max_sequence_length =256\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JpL1J65SpIv-"
      },
      "outputs": [],
      "source": [
        "Input_data = train_df[['context_ids','question_ids','label_idx']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cNFhGWXwoU6_"
      },
      "outputs": [],
      "source": [
        "training_data, Val_data = train_test_split(Input_data, test_size=0.2, random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "26Hb-jQdpGWx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jYYolzCYooM6"
      },
      "outputs": [],
      "source": [
        "train_context_sequences = training_data['context_ids']\n",
        "train_context_sequences = tf.keras.preprocessing.sequence.pad_sequences(train_context_sequences, maxlen=max_contex_length,padding='post')\n",
        "train_question_sequences = training_data['question_ids']\n",
        "train_question_sequences = tf.keras.preprocessing.sequence.pad_sequences(train_question_sequences, maxlen=max_question_length,padding='post')\n",
        "train_Answer = training_data['label_idx']\n",
        "train_Ans_start = [i[0] for i in train_Answer]\n",
        "train_Ans_end = [i[1] for i in train_Answer]\n",
        "train_context_sequences_AA = np.array(train_context_sequences)\n",
        "train_question_sequences_AA = np.array(train_question_sequences)\n",
        "train_Ans_start_AA = np.array(train_Ans_start)\n",
        "#train_Ans_start_AA=train_Ans_start_AA.reshape(train_Ans_start_AA.shape[0],1)\n",
        "train_Ans_end_AA = np.array(train_Ans_end)\n",
        "#train_Ans_end_AA=train_Ans_end_AA.reshape(train_Ans_end_AA.shape[0],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M_9IjUOcpt3D"
      },
      "outputs": [],
      "source": [
        "val_context_sequences = Val_data['context_ids']\n",
        "val_context_sequences = tf.keras.preprocessing.sequence.pad_sequences(val_context_sequences, maxlen=max_contex_length,padding='post')\n",
        "val_question_sequences = Val_data['question_ids']\n",
        "val_question_sequences = tf.keras.preprocessing.sequence.pad_sequences(val_question_sequences, maxlen=max_question_length,padding='post')\n",
        "val_Answer = Val_data['label_idx']\n",
        "val_Ans_start = [i[0] for i in val_Answer]\n",
        "val_Ans_end = [i[1] for i in val_Answer]\n",
        "val_context_sequences_AA = np.array(val_context_sequences)\n",
        "val_question_sequences_AA = np.array(val_question_sequences)\n",
        "val_Ans_start_AA = np.array(val_Ans_start)\n",
        "#val_Ans_start_AA=val_Ans_start_AA.reshape(val_Ans_start_AA.shape[0],1)\n",
        "val_Ans_end_AA = np.array(val_Ans_end)\n",
        "#val_Ans_end_AA=val_Ans_end_AA.reshape(val_Ans_end_AA.shape[0],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nNqAwfPEGAj",
        "outputId": "7385cde5-899f-42cf-c445-86715524760a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_question_sequences[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPa54v_TElMm",
        "outputId": "9423973a-b5ef-4745-9303-9eb957ddc726"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([43,  9,  1, ..., 46, 10, 82])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Ans_start_AA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Pxp2BoDYqTnb"
      },
      "outputs": [],
      "source": [
        "#MODEL\n",
        "context_input = Input(shape=(None,), dtype='int32', name='context_input')\n",
        "question_input = Input(shape=(None,), dtype='int32', name='question_input')\n",
        "embedding_layer = Embedding(input_dim=len(word2idx), output_dim=100, \n",
        "                            weights=[word_embeddings], trainable=False, mask_zero=True)\n",
        "context_embedded = embedding_layer(context_input)\n",
        "question_embedded = embedding_layer(question_input)\n",
        "lstm_layer1 = Bidirectional(LSTM(256, return_sequences=True))\n",
        "#lstm_layer2 = Bidirectional(LSTM(256, return_sequences=True))\n",
        "context_output = lstm_layer1(context_embedded)\n",
        "question_output = lstm_layer1(question_embedded)\n",
        "# Multi-head attention layer\n",
        "attention_output = Attention()([context_output, question_output])\n",
        "concat_output = Concatenate(axis=-1)([context_output, attention_output])\n",
        "\n",
        "# Dropout layer for regularization\n",
        "dropout_layer = Dropout(0.2)(concat_output)\n",
        "#dense1 = Dense(1024, activation='softmax', name='dense1')(dropout_layer)\n",
        "#dense2 = Dense(1024, activation='softmax', name='start_output')(dense1)\n",
        "# Output layers for start and end position prediction\n",
        "start_output = Dense(1, activation='softmax', name='start_output')(dropout_layer)\n",
        "end_output = Dense(1, activation='softmax', name='end_output')(dropout_layer)\n",
        "model = Model(inputs=[context_input, question_input], outputs=[start_output, end_output])\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV9mdcW1GvYL",
        "outputId": "f61c9130-e09b-47b6-a48f-90b6a671f5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " context_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " question_input (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 100)    9420000     ['context_input[0][0]',          \n",
            "                                                                  'question_input[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, None, 512)    731136      ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, None, 512)    0           ['bidirectional[0][0]',          \n",
            "                                                                  'bidirectional[1][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, 1024)   0           ['bidirectional[0][0]',          \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 1024)   0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " start_output (Dense)           (None, None, 1)      1025        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " end_output (Dense)             (None, None, 1)      1025        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,153,186\n",
            "Trainable params: 733,186\n",
            "Non-trainable params: 9,420,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Nl84qtlyqbde"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('model.h5', save_best_only=True, save_weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cDjX_Nbqeee",
        "outputId": "77f6708c-2196-4d75-9d90-b91d0f2b7fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "4184/4184 [==============================] - 203s 43ms/step - loss: 11955.7217 - start_output_loss: 5819.3452 - end_output_loss: 6136.3799 - start_output_accuracy: 0.0174 - end_output_accuracy: 0.0146 - val_loss: 11889.1660 - val_start_output_loss: 5785.1328 - val_end_output_loss: 6104.0327 - val_start_output_accuracy: 0.0191 - val_end_output_accuracy: 0.0163\n",
            "Epoch 2/5\n",
            "4184/4184 [==============================] - 179s 43ms/step - loss: 11955.7305 - start_output_loss: 5819.3452 - end_output_loss: 6136.3867 - start_output_accuracy: 0.0174 - end_output_accuracy: 0.0147 - val_loss: 11889.1660 - val_start_output_loss: 5785.1328 - val_end_output_loss: 6104.0327 - val_start_output_accuracy: 0.0191 - val_end_output_accuracy: 0.0163\n",
            "Epoch 3/5\n",
            "4184/4184 [==============================] - 177s 42ms/step - loss: 11955.7373 - start_output_loss: 5819.3481 - end_output_loss: 6136.3970 - start_output_accuracy: 0.0174 - end_output_accuracy: 0.0147 - val_loss: 11889.1660 - val_start_output_loss: 5785.1328 - val_end_output_loss: 6104.0327 - val_start_output_accuracy: 0.0191 - val_end_output_accuracy: 0.0163\n",
            "Epoch 4/5\n",
            "4184/4184 [==============================] - 177s 42ms/step - loss: 11955.7344 - start_output_loss: 5819.3467 - end_output_loss: 6136.3760 - start_output_accuracy: 0.0174 - end_output_accuracy: 0.0147 - val_loss: 11889.1660 - val_start_output_loss: 5785.1328 - val_end_output_loss: 6104.0327 - val_start_output_accuracy: 0.0191 - val_end_output_accuracy: 0.0163\n",
            "Epoch 5/5\n",
            "4184/4184 [==============================] - 178s 43ms/step - loss: 11955.7256 - start_output_loss: 5819.3457 - end_output_loss: 6136.3789 - start_output_accuracy: 0.0174 - end_output_accuracy: 0.0146 - val_loss: 11889.1660 - val_start_output_loss: 5785.1328 - val_end_output_loss: 6104.0327 - val_start_output_accuracy: 0.0191 - val_end_output_accuracy: 0.0163\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([train_context_sequences_AA, train_question_sequences_AA], [train_Ans_start_AA, train_Ans_end_AA], \n",
        "                    validation_data=([val_context_sequences_AA, val_question_sequences_AA], [val_Ans_start_AA, val_Ans_end_AA]),\n",
        "                    epochs=5, batch_size=16, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aOl9xHDpqwYg"
      },
      "outputs": [],
      "source": [
        "model.save('final_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a9D0kvtdV1qG"
      },
      "outputs": [],
      "source": [
        "with open('/trainHistoryDict', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
